{
    "kashish_resume.json": {
      "education": "Northeastern University - Master's, Electrical and Computer Engineering\nCoursework: Fundamentals of Computer Engineering (Teaching Assistant – Fall'24), Machine Learning and Pattern Recognition, Natural Language Processing, Data Management, Small Data for ML, Parallel Processing, Data Visualization, MLOps\n\nUniversity of Mumbai - Bachelor's, Electronics and Telecommunication Engineering\nCoursework: Data Structure and Algorithms, Python for Data Science, Big Data Analysis, Business Analytics, Artificial Intelligence",
      
      "experience": "KAP Ventures - Machine Learning Engineer (May 2025 - Present)\n- Implemented agentic AI workflows using LLaMA and GPT to power autonomous fashion styling assistants, driving social media growth from 0 to 20K+ followers and tripling user engagement within 2 months through dynamic, conversation-led experiences\n- Deployed NLP microservices via FastAPI and AWS Lambda, reducing inference latency by 40% and enhancing real-time recommendations\n\nNortheastern University - Assistant AI Researcher (Aug 2024 - Dec 2024)\n- Researched infant neurodevelopment using 3D pose estimation models (Meta's SAPIENS, SMPL, SMIL) to support autism diagnostics in collaboration with cross-functional research teams\n- Created 2D skeleton-based pipelines with Pyskl, converting 6+ hours of raw video into structured CSV datasets for behavior classification\n- Processed and refined SSBD data with Pandas, NumPy, and OpenCV, reducing 50% size and accelerating preprocessing by 87%\n- Supported university-led clinical research by aligning biomechanical analysis with ADOS scoring and documentation standards\n\nNortheastern University - Data Scientist - Assistant Researcher (Mar 2024 - Jun 2024)\n- Conducted deep learning experiments using TensorFlow and Keras, increasing classification accuracy by 18% on over 500 diagnostic samples, tracked experiments with MLflow and versioned pipelines using DVC to support reproducibility and model iteration\n- Organized scalable ETL flows for over 200GB sensor data using Pandas and NumPy, reducing preprocessing time by 60% and enabling deployment through Docker and Kubernetes\n\nKleren Oak - Fullstack Software Engineer (Apr 2021 - Mar 2023)\n- Launched 10+ production-ready applications using ReactJS, MongoDB and Firebase, reducing 20% delivery time and 30% load time\n- Optimized backend APIs using Postman and PyTest, improving query speed by 25% and reducing bug resolution time by 40%",
      
      "skills": "Programming Languages: Python, C++, C#, C Programming, Java, HTML, MATLAB, JavaScript, SQL, Scala, TypeScript\nML and Data Science: TensorFlow, Keras, PyTorch, scikit-learn, XGBoost, Transformers, Pandas, Numpy, OpenCV, PySpark\nData Engineering & MLOps: Spark, Hadoop, Airflow, MLflow, DVC, FastAPI, Streamlit\nWeb Development: ReactJS, Next.js, Node.js, Express.js, Firebase, Tailwind CSS\nDatabases & APIs: REST APIs, PostgreSQL, GraphQL, MongoDB\nCloud & DevOps: Docker, Kubernetes, Digital Ocean, Jenkins, CI/CD, AWS (EC2, S3, Lambda), Vercel\nVisualization: Tableau, PowerBI, Matplotlib, Seaborn, Plotly",
      
      "projects": "Breast Cancer Detection Using Transfer Learning Approach\n- Applied CNN-based transfer-learning for cancer classification, achieving 85.48% accuracy on the MIAS data (322 images)\n- Integrated VGG16, VGG19, Inception-V3, and ResNet50 with preprocessing techniques and expanded the dataset 8x through augmentation, reducing computation by 30% and lowering false positives by 15%\n- Evaluated performance using F1-score (0.92), AUC, precision, and recall, contributing to AI-assisted diagnostic improvements\n\nMindScope - Mental Health Dashboard\n- Built a real-time, user-centric NLP dashboard with Streamlit, processing 10K+ mental health–related tweets/day and achieving 92% sentiment classification accuracy using VADER, NRCLex, and BERTopic, while maintaining relevant documentation\n- Applied critical thinking and optimization skills to architect robust preprocessing workflows with spaCy, Pandas, and NLTK, reducing execution time by 35% and enabling 6+ interactive data visualizations for social insight exploration"
    },
  
    "software_engineer_resume.json": {
      "education": "Stanford University - Master's in Computer Science (2022)\nCoursework: Advanced Algorithms, Distributed Systems, Machine Learning, Computer Graphics\n\nUC Berkeley - Bachelor's in Electrical Engineering and Computer Science (2020)\nCoursework: Data Structures, Operating Systems, Database Systems, Software Engineering",
      
      "experience": "Google - Senior Software Engineer (Jan 2023 - Present)\n- Led development of distributed search indexing system serving 10B+ queries daily, improving response time by 35% through advanced caching and parallel processing\n- Implemented C++ microservices architecture with gRPC, reducing latency by 50% and increasing throughput by 200%\n- Mentored team of 5 junior engineers on algorithms, system design, and code review best practices\n\nMeta - Software Engineer (Jun 2022 - Dec 2022)\n- Built real-time recommendation engine using PyTorch and TensorFlow, increasing user engagement by 25%\n- Developed scalable data pipelines processing 100TB+ daily using Spark and Kubernetes\n- Collaborated with cross-functional teams to deliver machine learning features to 2B+ users\n\nMicrosoft - Software Engineering Intern (Summer 2021)\n- Created automated testing framework reducing deployment bugs by 40% using C# and Azure DevOps\n- Optimized database queries improving application performance by 60%\n- Participated in Agile development cycles with code reviews and sprint planning",
      
      "skills": "Programming Languages: C++, Python, Java, C#, JavaScript, Go, Rust\nFrameworks & Libraries: React, Node.js, Django, Flask, PyTorch, TensorFlow\nDatabases: PostgreSQL, MySQL, MongoDB, Redis, Cassandra\nCloud & DevOps: AWS, GCP, Azure, Docker, Kubernetes, Jenkins, Git\nTools: Linux, Vim, VS Code, Jira, Confluence\nConcepts: Algorithms, Data Structures, System Design, Machine Learning, Distributed Systems",
      
      "projects": "Distributed Chat Application\n- Built scalable real-time chat system supporting 50K+ concurrent users using Go and WebSockets\n- Implemented message persistence with Redis and PostgreSQL, ensuring 99.9% uptime\n- Deployed on AWS with auto-scaling, load balancing, and monitoring\n\nAlgorithm Visualizer\n- Created interactive web application for visualizing sorting and graph algorithms using React and D3.js\n- Implemented 15+ algorithms with step-by-step animations and complexity analysis\n- Deployed to production serving 10K+ monthly active users"
    },
  
    "data_scientist_resume.json": {
      "education": "MIT - Ph.D. in Applied Mathematics (2023)\nDissertation: Deep Learning Applications in Time Series Forecasting\nCoursework: Statistical Machine Learning, Optimization, Stochastic Processes\n\nCaltech - Master's in Statistics (2019)\nCoursework: Bayesian Statistics, Experimental Design, Multivariate Analysis\n\nHarvard - Bachelor's in Mathematics (2017)\nCoursework: Linear Algebra, Real Analysis, Probability Theory",
      
      "experience": "OpenAI - Senior Data Scientist (Mar 2023 - Present)\n- Developed novel transformer architectures for language models, improving performance by 15% on benchmark datasets\n- Led research on reinforcement learning from human feedback (RLHF), resulting in 2 published papers\n- Built distributed training pipelines using PyTorch and Ray, scaling to 1000+ GPUs\n\nNetflix - Data Scientist (Jan 2020 - Feb 2023)\n- Created recommendation algorithms serving 200M+ users, increasing engagement by 20%\n- Developed A/B testing framework for personalization experiments, running 100+ concurrent tests\n- Built real-time ML pipelines using Spark and Kafka, processing 10TB+ daily streaming data\n\nUber - Data Science Intern (Summer 2019)\n- Implemented demand forecasting models using XGBoost and LSTM, reducing prediction error by 25%\n- Analyzed rider behavior patterns using SQL and Python, identifying key growth opportunities\n- Created automated reporting dashboards in Tableau for executive decision making",
      
      "skills": "Programming Languages: Python, R, SQL, Scala, Java\nML/AI Frameworks: PyTorch, TensorFlow, scikit-learn, XGBoost, LightGBM, Hugging Face\nData Engineering: Spark, Kafka, Airflow, dbt, Snowflake, BigQuery\nVisualization: Matplotlib, Seaborn, Plotly, Tableau, Power BI\nCloud Platforms: AWS (SageMaker, EC2, S3), GCP (BigQuery, Vertex AI), Azure\nStatistics: Bayesian Methods, Hypothesis Testing, Causal Inference, Time Series Analysis\nTools: Jupyter, Git, Docker, Kubernetes, MLflow, Weights & Biases",
      
      "projects": "Stock Price Prediction System\n- Built ensemble model combining LSTM, ARIMA, and transformer architectures, achieving 85% directional accuracy\n- Implemented real-time data ingestion from financial APIs using Apache Kafka\n- Created interactive dashboard for portfolio optimization and risk analysis\n\nNLP Sentiment Analysis Platform\n- Developed multi-language sentiment classifier using BERT and custom transformers, supporting 12 languages\n- Achieved 94% accuracy on financial news sentiment classification\n- Deployed model serving API handling 1M+ requests daily with sub-100ms latency"
    },
  
    "devops_engineer_resume.json": {
      "education": "Georgia Tech - Master's in Computer Science (2021)\nSpecialization: Systems and Architecture\nCoursework: Distributed Systems, Cloud Computing, Network Security\n\nUT Austin - Bachelor's in Computer Engineering (2019)\nCoursework: Operating Systems, Computer Networks, Database Systems, Software Engineering",
      
      "experience": "Amazon Web Services - Senior DevOps Engineer (Aug 2022 - Present)\n- Architected and maintained infrastructure for services handling 1M+ requests per second using Terraform and CloudFormation\n- Implemented CI/CD pipelines reducing deployment time from hours to minutes, achieving 99.99% uptime\n- Led migration of 50+ microservices to Kubernetes, reducing infrastructure costs by 40%\n- Built comprehensive monitoring and alerting systems using Prometheus, Grafana, and CloudWatch\n\nSpotify - DevOps Engineer (Jun 2021 - Jul 2022)\n- Managed container orchestration for 200+ services using Docker and Kubernetes across multiple regions\n- Implemented Infrastructure as Code practices using Ansible and Terraform, managing 500+ servers\n- Optimized CI/CD workflows using Jenkins and GitLab CI, reducing build times by 60%\n- Collaborated with development teams to implement security best practices and compliance standards\n\nDropbox - Site Reliability Engineering Intern (Summer 2020)\n- Developed automated disaster recovery procedures reducing recovery time from 4 hours to 30 minutes\n- Created performance monitoring dashboards identifying and resolving bottlenecks proactively\n- Implemented log aggregation and analysis pipeline using ELK stack processing 100GB+ daily",
      
      "skills": "Cloud Platforms: AWS, GCP, Azure, DigitalOcean\nContainerization: Docker, Kubernetes, OpenShift, Helm\nInfrastructure as Code: Terraform, CloudFormation, Ansible, Pulumi\nCI/CD: Jenkins, GitLab CI, GitHub Actions, CircleCI, ArgoCD\nMonitoring: Prometheus, Grafana, ELK Stack, Datadog, New Relic\nScripting: Python, Bash, PowerShell, Go\nDatabases: PostgreSQL, MySQL, Redis, MongoDB, Elasticsearch\nNetworking: Load Balancers, VPC, DNS, CDN, Firewalls\nSecurity: SSL/TLS, OAuth, RBAC, Vulnerability Scanning",
      
      "projects": "Multi-Cloud Infrastructure Platform\n- Designed and implemented unified infrastructure management platform supporting AWS, GCP, and Azure\n- Built using Terraform modules and Kubernetes operators, managing 1000+ resources across clouds\n- Implemented cost optimization algorithms reducing cloud spend by 35% while maintaining performance\n\nAutomated Security Compliance System\n- Created end-to-end compliance automation for SOC2 and ISO27001 standards\n- Implemented infrastructure scanning, vulnerability assessment, and remediation workflows\n- Achieved 100% compliance audit success rate with 90% reduction in manual effort"
    }
  }